{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teaching a Language Model the Skill: Unstructured Text → Markdown Table\n",
    "\n",
    "Company X receives large volumes of user feedback through support emails, in-app surveys, and app store reviews. These messages often contain valuable product insights, but the content is unstructured and difficult to analyze at scale.\n",
    "\n",
    "To streamline internal workflows, an AI team at Company X wants to teach a language model how to convert raw user feedback into structured markdown tables. These tables summarize key topics, user sentiment, and issues in a format that’s easy to scan, report, or push into dashboards and tracking systems.\n",
    "\n",
    "We can do this using InstructLab!\n",
    "\n",
    "#### 🧾 Example Input and Output\n",
    "\n",
    "📥 Input (Unstructured Feedback)\n",
    "```\n",
    "Hey team — I’ve been using the new update for about a week now.\n",
    "\n",
    "Couple of things:\n",
    "- The dark mode is awesome, great job!\n",
    "- But the loading time after login feels slower than before. Not a deal breaker but noticeable.\n",
    "- I also noticed that the calendar widget doesn’t update properly if I change time zones.\n",
    "\n",
    "Overall, I love where this is going. Just needs a few tweaks.\n",
    "```\n",
    "📤 Output (Markdown Table)\n",
    "\n",
    "| Feature           | Feedback                                                               | Sentiment |\n",
    "|------------------|------------------------------------------------------------------------|-----------|\n",
    "| Dark Mode        | Works well, user is satisfied.                                          | Positive  |\n",
    "| Login Performance| Loading time after login is slower than previous version.               | Negative  |\n",
    "| Calendar Widget  | Doesn't update correctly when time zones change.                        | Negative  |\n",
    "| Overall          | User is happy with the direction of the product, but suggests tweaks.   | Positive  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧑‍🏫 Step 1: Serving Teacher Model\n",
    "\n",
    "This demo expects an openai compatible endpoint. You can use your favorite inference server like vLLM, HFInferenceServer, LlamaStack, etc. For more details on how to setup an inference server using vLLM, please refer to the [README](README.md).\n",
    "\n",
    "For this demo we will use meta-llama/Llama-3.3-70B-Instruct as our teacher model.\n",
    "\n",
    "#### Let's test the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful! meta-llama/Llama-3.3-70B-Instruct: Hello. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://0.0.0.0:8000/v1\"\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "models = client.models.list()\n",
    "teacher_model = models.data[0].id\n",
    "\n",
    "# Test the connection with a simple completion\n",
    "response = client.chat.completions.create(\n",
    "    model=teacher_model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}],\n",
    "    temperature=0.0,\n",
    "    max_tokens=10\n",
    ")\n",
    "completion = response.choices[0].message.content\n",
    "\n",
    "print(f\"Connection successful! {teacher_model}: {completion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✍️ Step 2: Provide Custom Examples\n",
    "\n",
    "As outlined in the LAB paper, the first step is to provide a small number of **seed examples** (typically 5) to bootstrap the skill. These examples are passed into the generation pipeline as input and are stored in a `qna.yaml` file.\n",
    "\n",
    "For this demo, we’ll use the pre-populated seed file located at: [unstructured_to_structured_qna.yaml](seed_data/unstructured_to_structured_qna.yaml)\n",
    "\n",
    "Lets convert the yaml into a jsonl file which can be used to bootstrap the skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from datasets import Dataset\n",
    "\n",
    "def convert_yaml_to_jsonl(yaml_path):\n",
    "    # Load YAML file\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        yaml_data = yaml.safe_load(f)\n",
    "    \n",
    "    # Extract examples into list of dicts\n",
    "    examples = []\n",
    "    for example in yaml_data['seed_examples']:\n",
    "        examples.append({\n",
    "            'task_description': yaml_data['task_description'],\n",
    "            'seed_context': example['context'],\n",
    "            'seed_question': example['question'],\n",
    "            'seed_response': example['answer']\n",
    "        })\n",
    "    \n",
    "    # Convert to HF Dataset\n",
    "    dataset = Dataset.from_list(examples)\n",
    "    return dataset\n",
    "\n",
    "# Load and convert the seed data\n",
    "seed_data = convert_yaml_to_jsonl('seed_data/unstructured_to_structured_qna.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────── Seed Data Example ───────────────────────────────────────────────╮\n",
       "│ <span style=\"font-weight: bold\">task_description:</span>                                                                                               │\n",
       "│                                                                                                                 │\n",
       "│ Convert the following unstructured user feedback into a structured markdown table.                              │\n",
       "│                                                                                                                 │\n",
       "│ <span style=\"font-weight: bold\">seed_context:</span>                                                                                                   │\n",
       "│                                                                                                                 │\n",
       "│ Been using the new dashboard for a few days. It's way faster than the previous one, really appreciate the       │\n",
       "│ snappy filters. But export to CSV seems broken — nothing happens when I click it. Also, dark mode resets every  │\n",
       "│ time I log in.                                                                                                  │\n",
       "│                                                                                                                 │\n",
       "│ <span style=\"font-weight: bold\">seed_question:</span>                                                                                                  │\n",
       "│                                                                                                                 │\n",
       "│ Convert the above feedback into a markdown table with columns for Feature, Feedback, and Sentiment?             │\n",
       "│                                                                                                                 │\n",
       "│ <span style=\"font-weight: bold\">seed_response:</span>                                                                                                  │\n",
       "│                                                                                                                 │\n",
       "│ | Feature           | Feedback                                                           | Sentiment |          │\n",
       "│ |------------------|--------------------------------------------------------------------|-----------|           │\n",
       "│ | Dashboard        | Much faster than previous version, filters are responsive.         | Positive  |           │\n",
       "│ | Export to CSV    | Clicking the export button doesn't trigger a download.             | Negative  |           │\n",
       "│ | Dark Mode        | Resets to light mode on login.                                     | Negative  |           │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────── Seed Data Example ───────────────────────────────────────────────╮\n",
       "│ \u001b[1mtask_description:\u001b[0m                                                                                               │\n",
       "│                                                                                                                 │\n",
       "│ Convert the following unstructured user feedback into a structured markdown table.                              │\n",
       "│                                                                                                                 │\n",
       "│ \u001b[1mseed_context:\u001b[0m                                                                                                   │\n",
       "│                                                                                                                 │\n",
       "│ Been using the new dashboard for a few days. It's way faster than the previous one, really appreciate the       │\n",
       "│ snappy filters. But export to CSV seems broken — nothing happens when I click it. Also, dark mode resets every  │\n",
       "│ time I log in.                                                                                                  │\n",
       "│                                                                                                                 │\n",
       "│ \u001b[1mseed_question:\u001b[0m                                                                                                  │\n",
       "│                                                                                                                 │\n",
       "│ Convert the above feedback into a markdown table with columns for Feature, Feedback, and Sentiment?             │\n",
       "│                                                                                                                 │\n",
       "│ \u001b[1mseed_response:\u001b[0m                                                                                                  │\n",
       "│                                                                                                                 │\n",
       "│ | Feature           | Feedback                                                           | Sentiment |          │\n",
       "│ |------------------|--------------------------------------------------------------------|-----------|           │\n",
       "│ | Dashboard        | Much faster than previous version, filters are responsive.         | Positive  |           │\n",
       "│ | Export to CSV    | Clicking the export button doesn't trigger a download.             | Negative  |           │\n",
       "│ | Dark Mode        | Resets to light mode on login.                                     | Negative  |           │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "from rich.panel import Panel\n",
    "\n",
    "print(Panel(\n",
    "    \"\\n\\n\".join(f\"[bold]{k}:[/bold] \\n\\n{v}\" for k,v in seed_data[0].items()),\n",
    "    title=\"Seed Data Example\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Step 3: Generate Synthetic Data\n",
    "\n",
    "Now that we have our seed data ready, we can use LAB’s Skill Data Generator to create **high-quality synthetic training examples** for our custom skill.\n",
    "\n",
    "This step leverages a predefined **flow configuration** that encodes how seed examples are expanded — by generating new contexts, questions, and responses, and filtering them for quality.\n",
    "\n",
    "In this demo, we'll use the `flows/unstructured_to_structured.yaml` pipeline to generate synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from instructlab.sdg.pipeline import Pipeline, PipelineContext\n",
    "from blocks import *\n",
    "\n",
    "ctx = PipelineContext(client=client, model_family=\"llama\", model_id=teacher_model)\n",
    "skills_pipe = Pipeline.from_file(ctx, os.path.join(os.getcwd(), \"flows/unstructured_to_structured.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8/8 [00:00<00:00, 2879.47 examples/s]\n",
      "Map: 100%|██████████| 8/8 [00:00<00:00, 3316.31 examples/s]\n",
      "Map: 100%|██████████| 8/8 [00:00<00:00, 3732.83 examples/s]\n",
      "Map: 100%|██████████| 8/8 [00:00<00:00, 3770.16 examples/s]\n",
      "Map: 100%|██████████| 8/8 [00:00<00:00, 3326.83 examples/s]\n",
      "Map: 100%|██████████| 8/8 [00:00<00:00, 3631.43 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 543.94 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 60.79 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 75.68 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 61.53 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 75.74 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 64.69 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 73.55 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 61.88 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 73.33 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 63.34 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 71.03 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 62.08 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 71.15 examples/s]\n",
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 306.96 examples/s]\n",
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n",
      "Filter: 100%|██████████| 1/1 [00:00<00:00, 385.72 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 61.01 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 73.31 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 60.79 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 72.92 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 61.14 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 72.10 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 60.77 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 72.89 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 50.98 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 70.43 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 60.22 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 74.09 examples/s]\n",
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 284.22 examples/s]\n",
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n",
      "Filter: 100%|██████████| 1/1 [00:00<00:00, 717.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "generated_data = skills_pipe.generate(seed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Step 4: Explore and Validate the Synthetically Generated Data\n",
    "\n",
    "Once the skill generation pipeline has been executed, the output is a set of **synthetically generated examples** — new context-question-response triples that follow the same structure as the seed data but are expanded and refined by the teacher model.\n",
    "\n",
    "Below is an example of one generated entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">Context:</span>                                                                                                        │\n",
       "│ Really enjoying the new features, especially the calendar integration which has been super helpful. However,    │\n",
       "│ I've noticed that the search function can be a bit slow and sometimes doesn't yield the expected results. Also, │\n",
       "│ the notification system could be more customizable, as I'm getting a lot of alerts that aren't relevant to me.  │\n",
       "│ Additionally, the app's battery usage seems a bit high, as my phone's battery drains faster when the app is     │\n",
       "│ running in the background.                                                                                      │\n",
       "│                                                                                                                 │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Question:</span>                                                                                                       │\n",
       "│ Convert the above feedback into a markdown table with columns for Feature, Feedback, and Sentiment?             │\n",
       "│                                                                                                                 │\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Response:</span>                                                                                                       │\n",
       "│ | Feature           | Feedback                                                             | Sentiment |        │\n",
       "│ |------------------|----------------------------------------------------------------------|-----------|         │\n",
       "│ | User Interface    | The design is modern and intuitive.                                 | Positive  |         │\n",
       "│ | Search Function   | Results are relevant, but loading time can be improved.              | Neutral   |        │\n",
       "│ | Customer Support  | Representatives are helpful, but response time is slow.              | Neutral   |        │\n",
       "│ | Payment Gateway   | Transaction process is secure, but options are limited.             | Neutral   |         │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ \u001b[1;38;5;214mContext:\u001b[0m                                                                                                        │\n",
       "│ Really enjoying the new features, especially the calendar integration which has been super helpful. However,    │\n",
       "│ I've noticed that the search function can be a bit slow and sometimes doesn't yield the expected results. Also, │\n",
       "│ the notification system could be more customizable, as I'm getting a lot of alerts that aren't relevant to me.  │\n",
       "│ Additionally, the app's battery usage seems a bit high, as my phone's battery drains faster when the app is     │\n",
       "│ running in the background.                                                                                      │\n",
       "│                                                                                                                 │\n",
       "│ \u001b[1;36mQuestion:\u001b[0m                                                                                                       │\n",
       "│ Convert the above feedback into a markdown table with columns for Feature, Feedback, and Sentiment?             │\n",
       "│                                                                                                                 │\n",
       "│ \u001b[1;32mResponse:\u001b[0m                                                                                                       │\n",
       "│ | Feature           | Feedback                                                             | Sentiment |        │\n",
       "│ |------------------|----------------------------------------------------------------------|-----------|         │\n",
       "│ | User Interface    | The design is modern and intuitive.                                 | Positive  |         │\n",
       "│ | Search Function   | Results are relevant, but loading time can be improved.              | Neutral   |        │\n",
       "│ | Customer Support  | Representatives are helpful, but response time is slow.              | Neutral   |        │\n",
       "│ | Payment Gateway   | Transaction process is secure, but options are limited.             | Neutral   |         │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[97m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from rich.panel import Panel\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "rand_idx = random.choice(range(len(generated_data)))\n",
    "\n",
    "# Pretty print the generated examples using rich\n",
    "example = generated_data[rand_idx]\n",
    "console.print(Panel.fit(\n",
    "    f\"[bold orange1]Context:[/bold orange1]\\n{example['context']}\\n\\n\"\n",
    "    f\"[bold cyan]Question:[/bold cyan]\\n{example['question']}\\n\\n\" \n",
    "    f\"[bold green]Response:[/bold green]\\n{example['response']}\"\n",
    "))\n",
    "console.rule(style=\"bright_white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏁 Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to teach a custom skill to a language model using the InstructLab Skill Data Generator (SDG). Starting from a small set of seed examples, we walked through the full synthetic data generation pipeline — including context creation, question generation, response synthesis, evaluation, and filtering.\n",
    "\n",
    "We explored a real-world use case: **transforming unstructured user feedback into structured markdown tables**, and showed how the LAB framework can automate the generation of high-quality, instructional training data at scale.\n",
    "\n",
    "This approach is especially powerful for procedural or domain-specific tasks where labeled data is scarce but consistent task logic can be modeled. With just a few carefully curated seed examples, you can unlock scalable skill creation and push new capabilities into LLMs with minimal manual effort.\n",
    "\n",
    "You’re now ready to use these synthetic examples for Fine-tuning small models! \n",
    "\n",
    "Next steps? \n",
    "\n",
    "* Try changing the parameters of the flow to see how the generated data changes (e.g. change the `num_samples` or try generating with different temperature)\n",
    "* Try adapting this pipeline to your own task, domain, or format — whether it’s triaging support tickets, extracting structured data, or following domain-specific workflows. The skills are yours to create."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilsdg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
