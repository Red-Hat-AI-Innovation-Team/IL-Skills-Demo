{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teaching a Language Model the Skill: Unstructured Text → Markdown Table\n",
    "\n",
    "Company X receives large volumes of user feedback through support emails, in-app surveys, and app store reviews. These messages often contain valuable product insights, but the content is unstructured and difficult to analyze at scale.\n",
    "\n",
    "To streamline internal workflows, an AI team at Company X wants to teach a language model how to convert raw user feedback into structured markdown tables. These tables summarize key topics, user sentiment, and issues in a format that’s easy to scan, report, or push into dashboards and tracking systems.\n",
    "\n",
    "We can do this using InstructLab!\n",
    "\n",
    "#### 🧾 Example Input and Output\n",
    "\n",
    "📥 Input (Unstructured Feedback)\n",
    "```\n",
    "Hey team — I’ve been using the new update for about a week now.\n",
    "\n",
    "Couple of things:\n",
    "- The dark mode is awesome, great job!\n",
    "- But the loading time after login feels slower than before. Not a deal breaker but noticeable.\n",
    "- I also noticed that the calendar widget doesn’t update properly if I change time zones.\n",
    "\n",
    "Overall, I love where this is going. Just needs a few tweaks.\n",
    "```\n",
    "📤 Output (Markdown Table)\n",
    "\n",
    "| Feature           | Feedback                                                               | Sentiment |\n",
    "|------------------|------------------------------------------------------------------------|-----------|\n",
    "| Dark Mode        | Works well, user is satisfied.                                          | Positive  |\n",
    "| Login Performance| Loading time after login is slower than previous version.               | Negative  |\n",
    "| Calendar Widget  | Doesn't update correctly when time zones change.                        | Negative  |\n",
    "| Overall          | User is happy with the direction of the product, but suggests tweaks.   | Positive  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: Setting up data generation pipeline\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    A[Flows] --> B[Blocks] --> C[Prompts]\n",
    "    C --> D[Synthetic Data!]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧑‍🏫 Step 1: Serving Teacher Model\n",
    "\n",
    "This demo expects an openai compatible endpoint. You can use your favorite inference server like vLLM, HFInferenceServer, LlamaStack, etc. For more details on how to setup an inference server using vLLM, please refer to the [README](README.md).\n",
    "\n",
    "For this demo we will use meta-llama/Llama-3.3-70B-Instruct as our teacher model.\n",
    "\n",
    "#### Let's test the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful! meta-llama/Llama-3.3-70B-Instruct: Hello. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://150.239.209.43:8008/v1\"\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "models = client.models.list()\n",
    "teacher_model = models.data[0].id\n",
    "\n",
    "# Test the connection with a simple completion\n",
    "response = client.chat.completions.create(\n",
    "    model=teacher_model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}],\n",
    "    temperature=0.0,\n",
    "    max_tokens=10\n",
    ")\n",
    "completion = response.choices[0].message.content\n",
    "\n",
    "print(f\"Connection successful! {teacher_model}: {completion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✍️ Step 2: Provide Custom Examples\n",
    "\n",
    "As outlined in the LAB paper, the first step is to provide a small number of **seed examples** (typically 5) to bootstrap the skill. These examples are passed into the generation pipeline as input and are stored in a `qna.yaml` file.\n",
    "\n",
    "For this demo, we’ll use the pre-populated seed file located at: [unstructured_to_structured_qna.yaml](seed_data/unstructured_to_structured_qna.yaml)\n",
    "\n",
    "```yaml\n",
    " version: 3\n",
    " created_by: Red Hat AI Innovation Team\n",
    " domain: Information Extraction\n",
    " seed_examples:\n",
    " - answer: |\n",
    "     | Feature           | Feedback                                                           | Sentiment |\n",
    "     |------------------|--------------------------------------------------------------------|-----------|\n",
    "     | Dashboard        | Much faster than previous version, filters are responsive.         | Positive  |\n",
    "     | Export to CSV    | Clicking the export button doesn't trigger a download.             | Negative  |\n",
    "     | Dark Mode        | Resets to light mode on login.                                     | Negative  |\n",
    "   context: >-\n",
    "     Been using the new dashboard for a few days. It's way faster than the\n",
    "     previous one, really appreciate the snappy filters. But export to CSV seems\n",
    "     broken — nothing happens when I click it. Also, dark mode resets every\n",
    "     time I log in.\n",
    "   question: Convert the above feedback into a markdown table with columns for Feature, Feedback, and Sentiment?\n",
    "```\n",
    "\n",
    "Lets convert the yaml into a jsonl file which can be used to bootstrap the skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab/.conda/envs/ilsdg/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────── Seed Data Example ───────────────────────────────────────────────╮\n",
       "│ <span style=\"font-weight: bold\">task_description:</span>                                                                                               │\n",
       "│                                                                                                                 │\n",
       "│ Convert the following unstructured user feedback into a structured markdown table.                              │\n",
       "│                                                                                                                 │\n",
       "│ <span style=\"font-weight: bold\">seed_context:</span>                                                                                                   │\n",
       "│                                                                                                                 │\n",
       "│ Been using the new dashboard for a few days. It's way faster than the previous one, really appreciate the       │\n",
       "│ snappy filters. But export to CSV seems broken — nothing happens when I click it. Also, dark mode resets every  │\n",
       "│ time I log in.                                                                                                  │\n",
       "│                                                                                                                 │\n",
       "│ <span style=\"font-weight: bold\">seed_question:</span>                                                                                                  │\n",
       "│                                                                                                                 │\n",
       "│ Convert the above feedback into a markdown table with columns for Feature, Feedback, and Sentiment?             │\n",
       "│                                                                                                                 │\n",
       "│ <span style=\"font-weight: bold\">seed_response:</span>                                                                                                  │\n",
       "│                                                                                                                 │\n",
       "│ | Feature           | Feedback                                                           | Sentiment |          │\n",
       "│ |------------------|--------------------------------------------------------------------|-----------|           │\n",
       "│ | Dashboard        | Much faster than previous version, filters are responsive.         | Positive  |           │\n",
       "│ | Export to CSV    | Clicking the export button doesn't trigger a download.             | Negative  |           │\n",
       "│ | Dark Mode        | Resets to light mode on login.                                     | Negative  |           │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────── Seed Data Example ───────────────────────────────────────────────╮\n",
       "│ \u001b[1mtask_description:\u001b[0m                                                                                               │\n",
       "│                                                                                                                 │\n",
       "│ Convert the following unstructured user feedback into a structured markdown table.                              │\n",
       "│                                                                                                                 │\n",
       "│ \u001b[1mseed_context:\u001b[0m                                                                                                   │\n",
       "│                                                                                                                 │\n",
       "│ Been using the new dashboard for a few days. It's way faster than the previous one, really appreciate the       │\n",
       "│ snappy filters. But export to CSV seems broken — nothing happens when I click it. Also, dark mode resets every  │\n",
       "│ time I log in.                                                                                                  │\n",
       "│                                                                                                                 │\n",
       "│ \u001b[1mseed_question:\u001b[0m                                                                                                  │\n",
       "│                                                                                                                 │\n",
       "│ Convert the above feedback into a markdown table with columns for Feature, Feedback, and Sentiment?             │\n",
       "│                                                                                                                 │\n",
       "│ \u001b[1mseed_response:\u001b[0m                                                                                                  │\n",
       "│                                                                                                                 │\n",
       "│ | Feature           | Feedback                                                           | Sentiment |          │\n",
       "│ |------------------|--------------------------------------------------------------------|-----------|           │\n",
       "│ | Dashboard        | Much faster than previous version, filters are responsive.         | Positive  |           │\n",
       "│ | Export to CSV    | Clicking the export button doesn't trigger a download.             | Negative  |           │\n",
       "│ | Dark Mode        | Resets to light mode on login.                                     | Negative  |           │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "from datasets import Dataset\n",
    "\n",
    "def convert_yaml_to_jsonl(yaml_path):\n",
    "    # Load YAML file\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        yaml_data = yaml.safe_load(f)\n",
    "    \n",
    "    # Extract examples into list of dicts\n",
    "    examples = []\n",
    "    for example in yaml_data['seed_examples']:\n",
    "        examples.append({\n",
    "            'task_description': yaml_data['task_description'],\n",
    "            'seed_context': example['context'],\n",
    "            'seed_question': example['question'],\n",
    "            'seed_response': example['answer']\n",
    "        })\n",
    "    \n",
    "    # Convert to HF Dataset\n",
    "    dataset = Dataset.from_list(examples)\n",
    "    return dataset\n",
    "\n",
    "# Load and convert the seed data\n",
    "seed_data = convert_yaml_to_jsonl('seed_data/unstructured_to_structured_qna.yaml')\n",
    "\n",
    "from rich import print\n",
    "from rich.panel import Panel\n",
    "\n",
    "print(Panel(\n",
    "    \"\\n\\n\".join(f\"[bold]{k}:[/bold] \\n\\n{v}\" for k,v in seed_data[0].items()),\n",
    "    title=\"Seed Data Example\"\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Step 3: Generate Synthetic Data\n",
    "\n",
    "Now that we have our seed data ready, we can use LAB’s Skill Data Generator to create **high-quality synthetic training examples** for our custom skill.\n",
    "\n",
    "This step leverages a predefined **flow configuration** that encodes how seed examples are expanded — by generating new contexts, questions, and responses, and filtering them for quality.\n",
    "\n",
    "In this demo, we'll use the `flows/unstructured_to_structured.yaml` pipeline to generate synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flows\n",
    "\n",
    "```mermaid\n",
    " flowchart LR\n",
    "     A[LLMBlock<br/>gen_contexts<br/>⟶ context] --> B[AddStaticValue<br/>add_question<br/>⟶ question]\n",
    "     B --> C[LLMBlock<br/>gen_responses<br/>⟶ response]\n",
    "     C --> D[LLMBlock<br/>evaluate_qa_pair<br/>⟶ evaluation, score]\n",
    "     D --> E[FilterByValueBlock<br/>filter_qa_pair<br/>score >= 2.0]\n",
    "     E --> F[Generated Data]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocks: Adding Custom Blocks\n",
    "\n",
    "One of the core design goals of SDG Hub is **modularity and extensibility**. Creating a new block is as simple as writing a Python class. Any Pythonic transformation or logic—no matter how simple or complex—can be encapsulated as a block and plugged into a pipeline.\n",
    "\n",
    "Here’s an example of how to create a custom block that adds a static value to every row in the dataset:\n",
    "\n",
    "```python\n",
    "@BlockRegistry.register(\"AddStaticValue\")\n",
    "class AddStaticValue(Block):\n",
    "    def __init__(self, ctx, pipe, block_name, column_name: str, static_value: str):\n",
    "        super().__init__(ctx, pipe, block_name)\n",
    "        self.column_name = column_name\n",
    "        self.static_value = static_value\n",
    "\n",
    "    @staticmethod\n",
    "    def _map_populate_column(samples, column_name, static_value, num_proc=1):\n",
    "        def populate_column(sample):\n",
    "            sample[column_name] = static_value\n",
    "            return sample\n",
    "\n",
    "        return samples.map(populate_column, num_proc=num_proc)\n",
    "\n",
    "    def generate(self, samples: Dataset) -> Dataset:\n",
    "        samples = self._map_populate_column(\n",
    "            samples, self.column_name, self.static_value\n",
    "        )\n",
    "        return samples\n",
    "```\n",
    "\n",
    "✨ Why This Matters\n",
    "* Simplicity: You can wrap any custom Python function into a block—no special framework or boilerplate needed.\n",
    "* Composable: Once registered, blocks can be easily used in your YAML workflows alongside LLM-based and filtering blocks.\n",
    "* Parallel-ready: Custom blocks can leverage the existing multiprocessing implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts \n",
    "\n",
    "```yaml\n",
    "system: You are a highly capable AI Assistant that specializes in generating high-quality content tailored to specific tasks.\n",
    "\n",
    "introduction: |\n",
    "  Your task is to write a rich, relevant, and well-structured **context** for the following task:\n",
    "  Task Description: {{task_description}}\n",
    "\n",
    "principles: |\n",
    "  Please follow these guiding principles when generating the context:\n",
    "  * The context should be coherent, informative, and closely aligned with the task description.\n",
    "  * Do not include any greetings, explanations, or meta commentary.\n",
    "  * Maintain a natural, human-like tone suitable for the domain.\n",
    "  * Follow the formatting shown in the example exactly.\n",
    "  * Wrap the output between the tags: [Start of Context] and [End of Context].\n",
    "\n",
    "examples: |\n",
    "  To guide you, here is an example of a well-structured context:\n",
    "  \n",
    "  [Start of Context]\n",
    "  {{seed_context}}\n",
    "  [End of Context]\n",
    "\n",
    "generation: |\n",
    "  Now generate a new context following the same structure and principles. \n",
    "  Begin your output with [Start of Context] and end with [End of Context]. \n",
    "  Do not include any additional text outside these tags.\n",
    "\n",
    "start_tags: [\"[Start of Context]\"]\n",
    "end_tags: [\"[End of Context]\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from instructlab.sdg.pipeline import Pipeline, PipelineContext\n",
    "from blocks import *\n",
    "\n",
    "ctx = PipelineContext(client=client, model_family=\"llama\", model_id=teacher_model)\n",
    "skills_pipe = Pipeline.from_file(ctx, os.path.join(os.getcwd(), \"flows/unstructured_to_structured.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8/8 [00:00<00:00, 3281.61 examples/s]\n",
      "Map: 100%|██████████| 8/8 [00:00<00:00, 3765.08 examples/s]\n",
      "Map: 100%|██████████| 8/8 [00:00<00:00, 4091.50 examples/s]\n",
      "Map: 100%|██████████| 8/8 [00:00<00:00, 4202.71 examples/s]\n",
      "Map: 100%|██████████| 8/8 [00:00<00:00, 4159.98 examples/s]\n",
      "Map: 100%|██████████| 8/8 [00:00<00:00, 3915.34 examples/s]\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 1105.36 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 54.49 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 66.77 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 57.70 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 67.49 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 56.44 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 68.41 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 56.99 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 67.80 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 54.96 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 65.80 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 57.62 examples/s]\n",
      "Filter (num_proc=8): 100%|██████████| 8/8 [00:00<00:00, 63.90 examples/s]\n",
      "num_proc must be <= 2. Reducing num_proc to 2 for dataset of size 2.\n",
      "Map (num_proc=2): 100%|██████████| 2/2 [00:00<00:00, 20.46 examples/s]\n",
      "num_proc must be <= 2. Reducing num_proc to 2 for dataset of size 2.\n",
      "Filter (num_proc=2): 100%|██████████| 2/2 [00:00<00:00, 20.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "generated_data = skills_pipe.generate(seed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Step 4: Explore and Validate the Synthetically Generated Data\n",
    "\n",
    "Once the skill generation pipeline has been executed, the output is a set of **synthetically generated examples** — new context-question-response triples that follow the same structure as the seed data but are expanded and refined by the teacher model.\n",
    "\n",
    "Below is an example of one generated entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">Context:</span>                                                                                                        │\n",
       "│ The application's search function is fast and mostly accurate. However, it sometimes fails to find recently     │\n",
       "│ added items. The filtering options are comprehensive, covering all necessary categories, but the interface      │\n",
       "│ could be more user-friendly. Occasionally, the application freezes when applying multiple filters               │\n",
       "│ simultaneously. Additionally, there's a noticeable lag when switching between different view modes.             │\n",
       "│                                                                                                                 │\n",
       "│ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Question:</span>                                                                                                       │\n",
       "│ Convert the above feedback into a markdown table with columns for Feature, Feedback, and Sentiment?             │\n",
       "│                                                                                                                 │\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Response:</span>                                                                                                       │\n",
       "│ | Feature           | Feedback                                                             | Sentiment |        │\n",
       "│ |------------------|----------------------------------------------------------------------|-----------|         │\n",
       "│ | AI Assistant     | Highly knowledgeable and precise in generating responses.            | Positive  |         │\n",
       "│ | Response Format  | Strictly follows the example format and style.                       | Positive  |         │\n",
       "│ | Relevance        | Accurately addresses the question and its intent.                   | Positive  |          │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ \u001b[1;38;5;214mContext:\u001b[0m                                                                                                        │\n",
       "│ The application's search function is fast and mostly accurate. However, it sometimes fails to find recently     │\n",
       "│ added items. The filtering options are comprehensive, covering all necessary categories, but the interface      │\n",
       "│ could be more user-friendly. Occasionally, the application freezes when applying multiple filters               │\n",
       "│ simultaneously. Additionally, there's a noticeable lag when switching between different view modes.             │\n",
       "│                                                                                                                 │\n",
       "│ \u001b[1;36mQuestion:\u001b[0m                                                                                                       │\n",
       "│ Convert the above feedback into a markdown table with columns for Feature, Feedback, and Sentiment?             │\n",
       "│                                                                                                                 │\n",
       "│ \u001b[1;32mResponse:\u001b[0m                                                                                                       │\n",
       "│ | Feature           | Feedback                                                             | Sentiment |        │\n",
       "│ |------------------|----------------------------------------------------------------------|-----------|         │\n",
       "│ | AI Assistant     | Highly knowledgeable and precise in generating responses.            | Positive  |         │\n",
       "│ | Response Format  | Strictly follows the example format and style.                       | Positive  |         │\n",
       "│ | Relevance        | Accurately addresses the question and its intent.                   | Positive  |          │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[97m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from rich.panel import Panel\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "rand_idx = random.choice(range(len(generated_data)))\n",
    "\n",
    "# Pretty print the generated examples using rich\n",
    "example = generated_data[rand_idx]\n",
    "console.print(Panel.fit(\n",
    "    f\"[bold orange1]Context:[/bold orange1]\\n{example['context']}\\n\\n\"\n",
    "    f\"[bold cyan]Question:[/bold cyan]\\n{example['question']}\\n\\n\" \n",
    "    f\"[bold green]Response:[/bold green]\\n{example['response']}\"\n",
    "))\n",
    "console.rule(style=\"bright_white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 Save the generated data\n",
    "\n",
    "```python\n",
    "generated_data.to_json(\"llama_generated_unstructured_to_structured.jsonl\", orient=\"records\", lines=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏁 Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to teach a custom skill to a language model using the InstructLab Skill Data Generator (SDG). Starting from a small set of seed examples, we walked through the full synthetic data generation pipeline — including context creation, question generation, response synthesis, evaluation, and filtering.\n",
    "\n",
    "We explored a real-world use case: **transforming unstructured user feedback into structured markdown tables**, and showed how the LAB framework can automate the generation of high-quality, instructional training data at scale.\n",
    "\n",
    "This approach is especially powerful for procedural or domain-specific tasks where labeled data is scarce but consistent task logic can be modeled. With just a few carefully curated seed examples, you can unlock scalable skill creation and push new capabilities into LLMs with minimal manual effort.\n",
    "\n",
    "You’re now ready to use these synthetic examples for Fine-tuning small models! \n",
    "\n",
    "Next steps? \n",
    "\n",
    "* Try changing the parameters of the flow to see how the generated data changes (e.g. change the `num_samples` or try generating with different temperature)\n",
    "* Try adapting this pipeline to your own task, domain, or format — whether it’s triaging support tickets, extracting structured data, or following domain-specific workflows. The skills are yours to create."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilsdg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
